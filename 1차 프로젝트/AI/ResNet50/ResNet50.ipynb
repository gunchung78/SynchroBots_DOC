{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97cc6405",
   "metadata": {},
   "source": [
    "1단계: 📁 데이터 준비 및 폴더 구조 확인<Br>\n",
    "PyTorch와 torchvision 라이브러리를 사용하여 이미지 분류를 수행하려면, 데이터 폴더 구조가 표준 형식(ImageFolder)을 따라야 합니다.\n",
    "\n",
    "✅ 폴더 구조 (예시)<Br>\n",
    "화살표 분류 프로젝트의 경우, train, val, test 세트 내부에 클래스 이름(예: 0 또는 1)으로 된 하위 폴더가 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50351bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. 하이퍼파라미터 및 경로 설정\n",
    "# 현재 사용하시는 경로에 맞춰 'root_dir'을 설정해 주세요.\n",
    "ROOT_DIR = 'C:/Dev/KAIROS_Project_1/ResNet50/data' \n",
    "BATCH_SIZE = 32 # VRAM 환경에 따라 조정 (YOLO보다 더 많은 메모리를 요구할 수 있음)\n",
    "NUM_WORKERS = 4 # 데이터 로드 속도를 위한 CPU 코어 수 (환경에 따라 0으로 설정 가능)\n",
    "IMG_SIZE = 224 # ResNet-50 표준 입력 크기 (224x224)\n",
    "\n",
    "# ResNet의 ImageNet 사전 학습 가중치에 맞춰 정규화 표준 사용\n",
    "NORM_MEAN = [0.485, 0.456, 0.406]\n",
    "NORM_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# 2. 전처리 파이프라인 정의\n",
    "transform = transforms.Compose([\n",
    "    # 이미지 크기를 256x256으로 조절\n",
    "    transforms.Resize(256),\n",
    "    # 224x224 크기로 중앙을 잘라냄 (Crop)\n",
    "    transforms.CenterCrop(IMG_SIZE), \n",
    "    # PIL Image를 PyTorch Tensor로 변환\n",
    "    transforms.ToTensor(),\n",
    "    # 정규화\n",
    "    transforms.Normalize(NORM_MEAN, NORM_STD)\n",
    "])\n",
    "\n",
    "# 3. 데이터셋 생성 및 로드\n",
    "def create_dataloaders(root_dir, batch_size, num_workers, transform):\n",
    "    \"\"\"\n",
    "    train, val, test 데이터 로더를 생성하는 함수\n",
    "    \"\"\"\n",
    "    # ImageFolder: 폴더 구조를 기반으로 데이터와 레이블을 자동 로드\n",
    "    train_dataset = ImageFolder(root=f'{root_dir}/train', transform=transform)\n",
    "    val_dataset = ImageFolder(root=f'{root_dir}/val', transform=transform)\n",
    "    test_dataset = ImageFolder(root=f'{root_dir}/test', transform=transform)\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    # 클래스 이름 확인\n",
    "    print(f\"✅ 클래스: {train_dataset.classes}\")\n",
    "    print(f\"✅ 학습 데이터셋 크기: {len(train_dataset)}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# 데이터 로더 실행\n",
    "train_loader, val_loader, test_loader = create_dataloaders(ROOT_DIR, BATCH_SIZE, NUM_WORKERS, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee1673f",
   "metadata": {},
   "source": [
    "[확인 사항] 현재 YOLO 프로젝트에서 사용하던 train/images, val/images가 아닌, 클래스별로 이미지를 분류한 위와 같은 구조로 데이터를 이동하거나 복사했는지 확인해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc1a8fa",
   "metadata": {},
   "source": [
    "2단계: ⚙️ 데이터 로더(DataLoader) 구현<br>\n",
    "데이터 로더는 이미지 파일을 읽고 전처리하며, 모델 학습에 필요한 배치(Batch) 단위로 데이터를 공급하는 역할을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # GPU가 사용 가능하면 인덱스 0번 GPU를 사용\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"✅ 사용 디바이스: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    # GPU가 없으면 CPU 사용\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"✅ 사용 디바이스: {device}\")\n",
    "\n",
    "# 2. 사전 학습된 ResNet-50 모델 로드\n",
    "# weights='ResNet50_Weights.IMAGENET1K_V1'는 최신 PyTorch에서 ImageNet 가중치를 로드하는 표준 방식입니다.\n",
    "model = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')\n",
    "\n",
    "# 3. 전이 학습을 위한 모델 수정\n",
    "# ResNet-50의 마지막 Fully Connected 레이어(fc)는 기본 1000개의 클래스(ImageNet)로 되어 있음\n",
    "num_ftrs = model.fc.in_features # fc 레이어의 입력 피처 수 확인\n",
    "\n",
    "# 프로젝트의 클래스 수(2개: '0', '1')에 맞게 새로운 fc 레이어로 교체\n",
    "model.fc = nn.Linear(num_ftrs, 2) \n",
    "\n",
    "# 4. 모델을 지정된 디바이스로 이동\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"✅ 모델 로드 및 수정 완료. 최종 출력 피처 수: {model.fc.out_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd4162b",
   "metadata": {},
   "source": [
    "3단계: 🧠 ResNet-50 모델 로드 및 수정<br>\n",
    "ResNet-50의 사전 학습된 가중치를 가져와, 화살표 두 클래스(0, 1)에 맞게 출력 레이어(fc 레이어)를 수정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b718a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# 1. 디바이스 설정 (YOLO와 동일하게 device=1을 가정)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and torch.cuda.device_count() >= 1 else \"cpu\")\n",
    "print(f\"✅ 사용 디바이스: {device}\")\n",
    "\n",
    "# 2. 사전 학습된 ResNet-50 모델 로드\n",
    "# weights='ResNet50_Weights.IMAGENET1K_V1'는 최신 PyTorch에서 ImageNet 가중치를 로드하는 표준 방식입니다.\n",
    "model = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')\n",
    "\n",
    "# 3. 전이 학습을 위한 모델 수정\n",
    "# ResNet-50의 마지막 Fully Connected 레이어(fc)는 기본 1000개의 클래스(ImageNet)로 되어 있음\n",
    "num_ftrs = model.fc.in_features # fc 레이어의 입력 피처 수 확인\n",
    "\n",
    "# 프로젝트의 클래스 수(2개: '0', '1')에 맞게 새로운 fc 레이어로 교체\n",
    "model.fc = nn.Linear(num_ftrs, 2) \n",
    "\n",
    "# 4. 모델을 지정된 디바이스로 이동\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"✅ 모델 로드 및 수정 완료. 최종 출력 피처 수: {model.fc.out_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff93eef",
   "metadata": {},
   "source": [
    "4단계: 📈 손실 함수(Loss) 및 최적화 도구(Optimizer) 정의<br>\n",
    "분류 문제에 적합한 도구를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29692806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 손실 함수: 분류에 주로 사용되는 교차 엔트로피(Cross Entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화 도구: AdamW 또는 SGD가 일반적으로 좋은 성능을 보임\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습률 스케줄러 (선택 사항): 학습이 진행됨에 따라 학습률을 점진적으로 낮춰 성능 개선\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8251f4c4",
   "metadata": {},
   "source": [
    "5단계: 🏃 학습 루프(Training Loop) 구현<br>\n",
    "실제 모델 학습이 진행되는 반복 루프입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87978217",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 5. 학습 루프 구현 및 F1-Score/Accuracy 기반 모델 저장 (수정됨)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# ... (상위 import 및 설정 부분은 이전 코드와 동일) ...\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_model\u001b[39m(model, criterion, optimizer, scheduler, num_epochs):\n\u001b[0;32m      9\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score # F1-Score 계산을 위해 추가\n",
    "from typing import Tuple, List, Dict \n",
    "\n",
    "# ==============================================================================\n",
    "# 1. 설정 및 하이퍼파라미터\n",
    "# ==============================================================================\n",
    "# ⚠️ 중요: 'ROOT_DIR'을 'data' 폴더가 있는 실제 경로로 수정하세요.\n",
    "ROOT_DIR = 'C:/Dev/KAIROS_Project_1/ResNet50/data' \n",
    "BATCH_SIZE = 32     \n",
    "NUM_CLASSES = 2     \n",
    "NUM_EPOCHS = 500    # 요청하신 500 에포크로 설정\n",
    "IMG_SIZE = 224      \n",
    "LR = 0.001          \n",
    "\n",
    "# ImageNet 표준 정규화 값\n",
    "NORM_MEAN = [0.485, 0.456, 0.406]\n",
    "NORM_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. 디바이스 설정 (GPU 사용 최적화)\n",
    "# ==============================================================================\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\") \n",
    "    print(f\"✅ 사용 디바이스: {torch.cuda.get_device_name(0)} (cuda:0)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"✅ 사용 디바이스: cpu\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. 전처리 및 데이터 로더 생성\n",
    "# ==============================================================================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(IMG_SIZE),        \n",
    "    transforms.RandomHorizontalFlip(),      \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(NORM_MEAN, NORM_STD)\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMG_SIZE), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(NORM_MEAN, NORM_STD)\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root=os.path.join(ROOT_DIR, 'train'), transform=train_transform)\n",
    "val_dataset = ImageFolder(root=os.path.join(ROOT_DIR, 'val'), transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"✅ 클래스: {train_dataset.classes}\")\n",
    "print(f\"✅ 학습/검증 데이터셋 크기: {len(train_dataset)} / {len(val_dataset)}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. ResNet-50 모델 로드, 수정, 학습 환경 정의\n",
    "# ==============================================================================\n",
    "model = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, NUM_CLASSES) \n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) \n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. 학습 루프 구현 및 F1-Score/Accuracy 기반 모델 저장 (수정됨)\n",
    "# ==============================================================================\n",
    "# ... (상위 import 및 설정 부분은 이전 코드와 동일) ...\n",
    "\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    start_time = time.time()\n",
    "    best_f1_score = -1.0  # 🌟 최고 F1-Score 추적\n",
    "    best_acc = -1.0       # 🌟 최고 Accuracy 추적\n",
    "    \n",
    "    save_dir = './resnet_saved_models'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 20)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            # ... (모델 모드 설정 및 데이터 로더 지정) ...\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()   \n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            all_preds = []   \n",
    "            all_labels = []  \n",
    "\n",
    "            for inputs, labels in dataloader:\n",
    "                # ... (순전파, 역전파 및 통계 계산 부분은 이전 코드와 동일) ...\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() \n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1) \n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            # 🌟🌟 저장 로직 (검증 단계에서만 실행)\n",
    "            if phase == 'val':\n",
    "                \n",
    "                current_f1_score = f1_score(all_labels, all_preds, zero_division=0) \n",
    "                current_acc = epoch_acc.item() # tensor에서 float으로 변환\n",
    "                \n",
    "                # 로그 출력용 CM 계산\n",
    "                try:\n",
    "                    cm = confusion_matrix(all_labels, all_preds)\n",
    "                    # cm.ravel() = [TN, FP, FN, TP]\n",
    "                    tn, fp, fn, tp = cm.ravel()\n",
    "                    cm_log = f\" (TN:{tn}, FP:{fp}, FN:{fn}, TP:{tp}, F1:{current_f1_score:.4f})\"\n",
    "                except ValueError:\n",
    "                    cm_log = f\" (F1:{current_f1_score:.4f})\"\n",
    "                \n",
    "                print(f\"  [Metric Score] F1:{current_f1_score:.4f}, Acc:{current_acc:.4f}{cm_log}\")\n",
    "                \n",
    "                \n",
    "                # 📌 저장 조건 1: F1과 Acc가 모두 1.0일 때 (완벽한 성능)\n",
    "                if current_f1_score >= 1.0 and current_acc >= 1.0:\n",
    "                    best_f1_score = current_f1_score # 최고 기록 업데이트\n",
    "                    best_acc = current_acc\n",
    "                    \n",
    "                    # 파일 이름을 'PERFECT_F1_Acc_에포크번호_타임스탬프.pth' 형식으로 지정\n",
    "                    model_save_path = os.path.join(save_dir, f'resnet50_PERFECT_e{epoch+1}_f1_1.0000_{timestamp}.pth') \n",
    "                    \n",
    "                    torch.save(model.state_dict(), model_save_path)\n",
    "                    \n",
    "                    print(f\"🎉🎉 퍼펙트 스코어 달성! 모델 가중치 저장 완료: {model_save_path}\")\n",
    "\n",
    "                \n",
    "                # 📌 저장 조건 2: 최고 기록 경신 (F1 우선, Acc는 F1이 같을 때만 비교)\n",
    "                elif current_f1_score > best_f1_score or (current_f1_score == best_f1_score and current_acc > best_acc):\n",
    "                    \n",
    "                    best_f1_score = current_f1_score\n",
    "                    best_acc = current_acc\n",
    "                    \n",
    "                    # 파일 이름을 'BEST_F1_Acc_타임스탬프.pth' 형식으로 지정\n",
    "                    model_save_path = os.path.join(save_dir, f'resnet50_BEST_e{epoch+1}_f1_{best_f1_score:.4f}_acc_{best_acc:.4f}_{timestamp}.pth') \n",
    "                    \n",
    "                    torch.save(model.state_dict(), model_save_path)\n",
    "                    \n",
    "                    print(f\"🌟 최고 성능 경신 (F1:{best_f1_score:.4f}, Acc:{best_acc:.4f}), 모델 가중치 저장 완료: {model_save_path}\")\n",
    "                \n",
    "                else:\n",
    "                    print(f\"❗ 최고 성능 경신 실패 (Best F1:{best_f1_score:.4f}, Best Acc:{best_acc:.4f})\")\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f'총 학습 시간: {time_elapsed // 60:.0f}분 {time_elapsed % 60:.0f}초')\n",
    "    print(f'최종 최고 F1-Score: {best_f1_score:.4f}, 최종 최고 Accuracy: {best_acc:.4f}')\n",
    "    return model\n",
    "\n",
    "# 🚀 학습 시작\n",
    "final_model = train_model(model, criterion, optimizer, scheduler, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
